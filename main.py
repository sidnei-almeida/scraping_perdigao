#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸ¦† SCRAPING PERDIGÃƒO - Interface CLI
=====================================
Sistema completo para coleta de dados nutricionais dos produtos da PerdigÃ£o

FUNCIONALIDADES:
1. ğŸ•·ï¸ Coletar URLs dos produtos
2. ğŸ“Š Extrair dados nutricionais
3. ğŸš€ Coleta completa (URLs + dados)
4. ğŸ“ Gerenciar arquivos gerados
"""

import os
import sys
import time
import glob
import subprocess
from datetime import datetime
from typing import List, Dict, Optional

# ============================================================================
# ğŸ¨ SISTEMA DE CORES ANSI PARA TERMINAL
# ============================================================================
class Cores:
    RESET = '\033[0m'
    BOLD = '\033[1m'
    VERDE = '\033[92m'
    AZUL = '\033[94m'
    AMARELO = '\033[93m'
    VERMELHO = '\033[91m'
    CIANO = '\033[96m'
    MAGENTA = '\033[95m'
    BRANCO = '\033[97m'

# ============================================================================
# ğŸ› ï¸ FUNÃ‡Ã•ES UTILITÃRIAS
# ============================================================================
def limpar_terminal():
    """Limpa o terminal"""
    os.system('clear' if os.name == 'posix' else 'cls')

def mostrar_banner():
    """Exibe o banner principal do programa"""
    banner = f"""
{Cores.CIANO}{Cores.BOLD}
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ¦† SCRAPING PERDIGÃƒO                      â•‘
â•‘                                                              â•‘
â•‘              Coleta de Dados Nutricionais v1.0              â•‘
â•‘                                                              â•‘
â•‘  ğŸ•·ï¸  Coleta URLs dos produtos                               â•‘
â•‘  ğŸ“Š ExtraÃ§Ã£o de dados nutricionais                          â•‘
â•‘  ğŸš€ Sistema completo de scraping                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{Cores.RESET}"""
    print(banner)

def mostrar_barra_progresso(texto: str, duracao: float = 2.0):
    """Exibe uma barra de progresso animada"""
    print(f"\n{Cores.AMARELO}â³ {texto}...{Cores.RESET}")
    barra_tamanho = 40
    for i in range(barra_tamanho + 1):
        progresso = i / barra_tamanho
        barra = "â–ˆ" * i + "â–‘" * (barra_tamanho - i)
        porcentagem = int(progresso * 100)
        print(f"\r{Cores.VERDE}[{barra}] {porcentagem}%{Cores.RESET}", end="", flush=True)
        time.sleep(duracao / barra_tamanho)
    print()

def mostrar_menu():
    """Exibe o menu principal"""
    menu = f"""
{Cores.AZUL}{Cores.BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• MENU PRINCIPAL â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{Cores.RESET}

{Cores.VERDE}ğŸš€ OPERAÃ‡Ã•ES PRINCIPAIS:{Cores.RESET}
  {Cores.AMARELO}1.{Cores.RESET} ğŸ•·ï¸  {Cores.BRANCO}Coletar URLs{Cores.RESET} - Extrair URLs dos produtos PerdigÃ£o
  {Cores.AMARELO}2.{Cores.RESET} ğŸ“Š {Cores.BRANCO}Extrair Dados{Cores.RESET} - Coletar dados nutricionais
  {Cores.AMARELO}3.{Cores.RESET} ğŸš€ {Cores.BRANCO}Coleta Completa{Cores.RESET} - URLs + dados nutricionais

{Cores.VERDE}ğŸ“ GERENCIAR DADOS:{Cores.RESET}
  {Cores.AMARELO}4.{Cores.RESET} ğŸ“‹ {Cores.BRANCO}Ver Arquivos{Cores.RESET} - Lista arquivos gerados
  {Cores.AMARELO}5.{Cores.RESET} ğŸ—‘ï¸  {Cores.BRANCO}Limpar Dados{Cores.RESET} - Remove arquivos antigos

{Cores.VERDE}â„¹ï¸  INFORMAÃ‡Ã•ES:{Cores.RESET}
  {Cores.AMARELO}6.{Cores.RESET} ğŸ“– {Cores.BRANCO}Sobre o Programa{Cores.RESET} - InformaÃ§Ãµes e estatÃ­sticas
  {Cores.AMARELO}7.{Cores.RESET} âŒ {Cores.BRANCO}Sair{Cores.RESET} - Encerrar programa

{Cores.AZUL}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{Cores.RESET}
"""
    print(menu)

def obter_escolha() -> str:
    """ObtÃ©m a escolha do usuÃ¡rio"""
    try:
        escolha = input(f"{Cores.MAGENTA}ğŸ‘‰ Digite sua opÃ§Ã£o (1-7): {Cores.RESET}").strip()
        return escolha
    except KeyboardInterrupt:
        print(f"\n\n{Cores.AMARELO}âš ï¸  Programa interrompido pelo usuÃ¡rio{Cores.RESET}")
        sys.exit(0)

# ============================================================================
# ğŸ¯ FUNÃ‡Ã•ES ESPECÃFICAS DO PROJETO
# ============================================================================

def executar_coleta_urls():
    """Coleta URLs dos produtos da PerdigÃ£o"""
    print(f"\n{Cores.CIANO}{Cores.BOLD}ğŸ•·ï¸  COLETANDO URLs DOS PRODUTOS{Cores.RESET}")
    print(f"{Cores.AZUL}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”{Cores.RESET}")
    
    print(f"\n{Cores.VERDE}âœ… ConfiguraÃ§Ãµes:{Cores.RESET}")
    print(f"   ğŸ“Š SeÃ§Ãµes: {Cores.AMARELO}12 categorias de produtos{Cores.RESET}")
    print(f"   ğŸ“ SaÃ­da: {Cores.AMARELO}dados/product_urls.json{Cores.RESET}")
    print(f"   â±ï¸  Tempo estimado: {Cores.AMARELO}2-3 minutos{Cores.RESET}")
    
    confirmar = input(f"\n{Cores.MAGENTA}ğŸ¤” Continuar? (s/N): {Cores.RESET}").lower()
    
    if confirmar in ['s', 'sim', 'y', 'yes']:
        try:
            mostrar_barra_progresso("Iniciando coleta de URLs", 1.0)
            
            # Executar o coletor de URLs
            resultado = subprocess.run([
                sys.executable, "config/url_collector.py"
            ], capture_output=True, text=True)
            
            if resultado.returncode == 0:
                print(f"{Cores.VERDE}âœ… URLs coletadas com sucesso!{Cores.RESET}")
                
                # Verificar se o arquivo foi criado
                if os.path.exists("dados/product_urls.json"):
                    with open("dados/product_urls.json", 'r', encoding='utf-8') as f:
                        import json
                        urls = json.load(f)
                    print(f"{Cores.VERDE}ğŸ“Š Total de URLs coletadas: {len(urls)}{Cores.RESET}")
                else:
                    print(f"{Cores.VERMELHO}âŒ Arquivo de URLs nÃ£o foi criado{Cores.RESET}")
            else:
                print(f"{Cores.VERMELHO}âŒ Erro na coleta: {resultado.stderr}{Cores.RESET}")
                
        except Exception as e:
            print(f"\n{Cores.VERMELHO}âŒ Erro durante execuÃ§Ã£o: {e}{Cores.RESET}")
    else:
        print(f"{Cores.AMARELO}â­ï¸  OperaÃ§Ã£o cancelada{Cores.RESET}")

def executar_extracao_dados():
    """Extrai dados nutricionais dos produtos"""
    print(f"\n{Cores.CIANO}{Cores.BOLD}ğŸ“Š EXTRAINDO DADOS NUTRICIONAIS{Cores.RESET}")
    print(f"{Cores.AZUL}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”{Cores.RESET}")
    
    # Verificar se existe arquivo de URLs
    if not os.path.exists("dados/product_urls.json"):
        print(f"{Cores.VERMELHO}âŒ Arquivo de URLs nÃ£o encontrado!{Cores.RESET}")
        print(f"{Cores.AMARELO}ğŸ’¡ Execute primeiro a opÃ§Ã£o 1 para coletar as URLs{Cores.RESET}")
        return
    
    # Carregar URLs
    try:
        with open("dados/product_urls.json", 'r', encoding='utf-8') as f:
            import json
            urls = json.load(f)
        
        print(f"\n{Cores.VERDE}âœ… ConfiguraÃ§Ãµes:{Cores.RESET}")
        print(f"   ğŸ“Š URLs carregadas: {Cores.AMARELO}{len(urls)}{Cores.RESET}")
        print(f"   ğŸ“ SaÃ­da: {Cores.AMARELO}dados/produtos_perdigao_TIMESTAMP.csv{Cores.RESET}")
        print(f"   â±ï¸  Tempo estimado: {Cores.AMARELO}5-10 minutos{Cores.RESET}")
        
        confirmar = input(f"\n{Cores.MAGENTA}ğŸ¤” Continuar? (s/N): {Cores.RESET}").lower()
        
        if confirmar in ['s', 'sim', 'y', 'yes']:
            try:
                mostrar_barra_progresso("Iniciando extraÃ§Ã£o de dados", 1.0)
                
                # Executar o scraper
                resultado = subprocess.run([
                    sys.executable, "config/scraper.py"
                ], capture_output=True, text=True)
                
                if resultado.returncode == 0:
                    print(f"{Cores.VERDE}âœ… Dados extraÃ­dos com sucesso!{Cores.RESET}")
                    
                    # Verificar arquivos CSV criados
                    csv_files = glob.glob("dados/produtos_perdigao_*.csv")
                    if csv_files:
                        latest_file = max(csv_files, key=os.path.getctime)
                        print(f"{Cores.VERDE}ğŸ“ Arquivo criado: {latest_file}{Cores.RESET}")
                    else:
                        print(f"{Cores.VERMELHO}âŒ Nenhum arquivo CSV foi criado{Cores.RESET}")
                else:
                    print(f"{Cores.VERMELHO}âŒ Erro na extraÃ§Ã£o: {resultado.stderr}{Cores.RESET}")
                    
            except Exception as e:
                print(f"\n{Cores.VERMELHO}âŒ Erro durante execuÃ§Ã£o: {e}{Cores.RESET}")
        else:
            print(f"{Cores.AMARELO}â­ï¸  OperaÃ§Ã£o cancelada{Cores.RESET}")
            
    except Exception as e:
        print(f"{Cores.VERMELHO}âŒ Erro ao carregar URLs: {e}{Cores.RESET}")

def executar_coleta_completa():
    """Executa coleta completa: URLs + dados nutricionais"""
    print(f"\n{Cores.CIANO}{Cores.BOLD}ğŸš€ COLETA COMPLETA{Cores.RESET}")
    print(f"{Cores.AZUL}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”{Cores.RESET}")
    
    print(f"\n{Cores.AMARELO}âš ï¸  ATENÃ‡ÃƒO:{Cores.RESET}")
    print(f"   â€¢ Esta operaÃ§Ã£o pode demorar {Cores.VERMELHO}10-15 minutos{Cores.RESET}")
    print(f"   â€¢ SerÃ£o executadas as etapas 1 e 2 em sequÃªncia")
    print(f"   â€¢ Certifique-se de ter uma conexÃ£o estÃ¡vel com a internet")
    
    confirmar = input(f"\n{Cores.MAGENTA}ğŸ¤” Continuar? (s/N): {Cores.RESET}").lower()
    
    if confirmar in ['s', 'sim', 'y', 'yes']:
        try:
            # Etapa 1: Coletar URLs
            print(f"\n{Cores.VERDE}ğŸ•·ï¸  ETAPA 1: Coletando URLs...{Cores.RESET}")
            mostrar_barra_progresso("Coletando URLs dos produtos", 2.0)
            
            resultado_urls = subprocess.run([
                sys.executable, "config/url_collector.py"
            ], capture_output=True, text=True)
            
            if resultado_urls.returncode != 0:
                print(f"{Cores.VERMELHO}âŒ Erro na coleta de URLs: {resultado_urls.stderr}{Cores.RESET}")
                return
            
            print(f"{Cores.VERDE}âœ… URLs coletadas com sucesso!{Cores.RESET}")
            
            # Etapa 2: Extrair dados
            print(f"\n{Cores.VERDE}ğŸ“Š ETAPA 2: Extraindo dados nutricionais...{Cores.RESET}")
            mostrar_barra_progresso("Extraindo dados nutricionais", 3.0)
            
            resultado_dados = subprocess.run([
                sys.executable, "config/scraper.py"
            ], capture_output=True, text=True)
            
            if resultado_dados.returncode == 0:
                print(f"{Cores.VERDE}âœ… Coleta completa finalizada com sucesso!{Cores.RESET}")
                
                # Verificar arquivos criados
                if os.path.exists("dados/product_urls.json"):
                    with open("dados/product_urls.json", 'r', encoding='utf-8') as f:
                        import json
                        urls = json.load(f)
                    print(f"{Cores.VERDE}ğŸ“Š URLs coletadas: {len(urls)}{Cores.RESET}")
                
                csv_files = glob.glob("dados/produtos_perdigao_*.csv")
                if csv_files:
                    latest_file = max(csv_files, key=os.path.getctime)
                    print(f"{Cores.VERDE}ğŸ“ Arquivo de dados: {latest_file}{Cores.RESET}")
            else:
                print(f"{Cores.VERMELHO}âŒ Erro na extraÃ§Ã£o de dados: {resultado_dados.stderr}{Cores.RESET}")
                
        except Exception as e:
            print(f"\n{Cores.VERMELHO}âŒ Erro: {e}{Cores.RESET}")
    else:
        print(f"{Cores.AMARELO}â­ï¸  OperaÃ§Ã£o cancelada{Cores.RESET}")

def listar_arquivos_gerados():
    """Lista arquivos gerados pelo programa"""
    print(f"\n{Cores.CIANO}{Cores.BOLD}ğŸ“‹ ARQUIVOS GERADOS{Cores.RESET}")
    print(f"{Cores.AZUL}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”{Cores.RESET}")
    
    pasta_dados = "dados"
    
    if not os.path.exists(pasta_dados):
        print(f"{Cores.AMARELO}ğŸ“ Pasta '{pasta_dados}' nÃ£o encontrada{Cores.RESET}")
        return
    
    # Listar arquivos JSON
    json_files = glob.glob(f"{pasta_dados}/*.json")
    csv_files = glob.glob(f"{pasta_dados}/*.csv")
    
    if not json_files and not csv_files:
        print(f"{Cores.AMARELO}ğŸ“„ Nenhum arquivo encontrado em '{pasta_dados}'{Cores.RESET}")
        return
    
    total_arquivos = len(json_files) + len(csv_files)
    print(f"\n{Cores.VERDE}ğŸ“Š Total de arquivos: {total_arquivos}{Cores.RESET}\n")
    
    # Listar arquivos JSON
    if json_files:
        print(f"{Cores.CIANO}ğŸ“„ Arquivos JSON:{Cores.RESET}")
        for i, arquivo in enumerate(sorted(json_files, reverse=True), 1):
            nome_arquivo = os.path.basename(arquivo)
            tamanho = os.path.getsize(arquivo)
            data_modificacao = datetime.fromtimestamp(os.path.getmtime(arquivo))
            
            if tamanho < 1024:
                tamanho_str = f"{tamanho} B"
            elif tamanho < 1024 * 1024:
                tamanho_str = f"{tamanho / 1024:.1f} KB"
            else:
                tamanho_str = f"{tamanho / (1024 * 1024):.1f} MB"
            
            print(f"{Cores.AMARELO}{i:2d}.{Cores.RESET} {Cores.BRANCO}{nome_arquivo}{Cores.RESET}")
            print(f"     ğŸ“… {data_modificacao.strftime('%d/%m/%Y %H:%M:%S')}")
            print(f"     ğŸ“ {tamanho_str}")
            print()
    
    # Listar arquivos CSV
    if csv_files:
        print(f"{Cores.CIANO}ğŸ“Š Arquivos CSV:{Cores.RESET}")
        for i, arquivo in enumerate(sorted(csv_files, reverse=True), 1):
            nome_arquivo = os.path.basename(arquivo)
            tamanho = os.path.getsize(arquivo)
            data_modificacao = datetime.fromtimestamp(os.path.getmtime(arquivo))
            
            if tamanho < 1024:
                tamanho_str = f"{tamanho} B"
            elif tamanho < 1024 * 1024:
                tamanho_str = f"{tamanho / 1024:.1f} KB"
            else:
                tamanho_str = f"{tamanho / (1024 * 1024):.1f} MB"
            
            print(f"{Cores.AMARELO}{i:2d}.{Cores.RESET} {Cores.BRANCO}{nome_arquivo}{Cores.RESET}")
            print(f"     ğŸ“… {data_modificacao.strftime('%d/%m/%Y %H:%M:%S')}")
            print(f"     ğŸ“ {tamanho_str}")
            print()

def limpar_dados_antigos():
    """Remove arquivos antigos"""
    print(f"\n{Cores.CIANO}{Cores.BOLD}ğŸ—‘ï¸  LIMPAR DADOS ANTIGOS{Cores.RESET}")
    print(f"{Cores.AZUL}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”{Cores.RESET}")
    
    pasta_dados = "dados"
    
    if not os.path.exists(pasta_dados):
        print(f"{Cores.AMARELO}ğŸ“ Pasta '{pasta_dados}' nÃ£o encontrada{Cores.RESET}")
        return
    
    json_files = glob.glob(f"{pasta_dados}/*.json")
    csv_files = glob.glob(f"{pasta_dados}/*.csv")
    total_arquivos = len(json_files) + len(csv_files)
    
    if total_arquivos == 0:
        print(f"{Cores.VERDE}âœ… Nenhum arquivo para limpar{Cores.RESET}")
        return
    
    print(f"\n{Cores.AMARELO}âš ï¸  ATENÃ‡ÃƒO:{Cores.RESET}")
    print(f"   â€¢ SerÃ£o removidos {Cores.VERMELHO}{total_arquivos} arquivos{Cores.RESET}")
    print(f"   â€¢ Esta aÃ§Ã£o {Cores.VERMELHO}NÃƒO PODE ser desfeita{Cores.RESET}")
    
    confirmar = input(f"\n{Cores.MAGENTA}ğŸ¤” Tem certeza? Digite 'CONFIRMAR' para prosseguir: {Cores.RESET}")
    
    if confirmar == "CONFIRMAR":
        try:
            for arquivo in json_files + csv_files:
                os.remove(arquivo)
            print(f"\n{Cores.VERDE}âœ… {total_arquivos} arquivos removidos com sucesso!{Cores.RESET}")
        except Exception as e:
            print(f"\n{Cores.VERMELHO}âŒ Erro ao remover arquivos: {e}{Cores.RESET}")
    else:
        print(f"{Cores.AMARELO}â­ï¸  OperaÃ§Ã£o cancelada{Cores.RESET}")

def mostrar_sobre():
    """Mostra informaÃ§Ãµes sobre o programa"""
    print(f"\n{Cores.CIANO}{Cores.BOLD}ğŸ“– SOBRE O PROGRAMA{Cores.RESET}")
    print(f"{Cores.AZUL}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”{Cores.RESET}")
    
    print(f"\n{Cores.VERDE}ğŸ¦† SCRAPING PERDIGÃƒO{Cores.RESET}")
    print(f"   VersÃ£o: {Cores.AMARELO}1.0{Cores.RESET}")
    print(f"   Desenvolvido para coleta de dados nutricionais")
    print(f"   dos produtos da PerdigÃ£o")
    
    print(f"\n{Cores.VERDE}ğŸ“Š FUNCIONALIDADES:{Cores.RESET}")
    print(f"   ğŸ•·ï¸  Coleta URLs de 12 categorias de produtos")
    print(f"   ğŸ“Š ExtraÃ§Ã£o de dados nutricionais completos")
    print(f"   ğŸš€ Sistema automatizado de scraping")
    
    print(f"\n{Cores.VERDE}ğŸ“ ESTRUTURA:{Cores.RESET}")
    print(f"   config/url_collector.py - Coletor de URLs")
    print(f"   config/scraper.py - Extrator de dados")
    print(f"   dados/ - Pasta de saÃ­da dos arquivos")
    
    print(f"\n{Cores.VERDE}ğŸ“‹ DADOS COLETADOS:{Cores.RESET}")
    print(f"   â€¢ Nome do produto")
    print(f"   â€¢ URL do produto")
    print(f"   â€¢ Categoria")
    print(f"   â€¢ PorÃ§Ã£o (g)")
    print(f"   â€¢ Calorias (kcal)")
    print(f"   â€¢ Carboidratos (g)")
    print(f"   â€¢ ProteÃ­nas (g)")
    print(f"   â€¢ Gorduras totais (g)")
    print(f"   â€¢ Gorduras saturadas (g)")
    print(f"   â€¢ Fibras (g)")
    print(f"   â€¢ AÃ§Ãºcares (g)")
    print(f"   â€¢ SÃ³dio (mg)")
    
    print(f"\n{Cores.VERDE}âš¡ TECNOLOGIAS:{Cores.RESET}")
    print(f"   â€¢ Python 3.13")
    print(f"   â€¢ Requests + BeautifulSoup")
    print(f"   â€¢ Pandas para manipulaÃ§Ã£o de dados")
    
    # EstatÃ­sticas dos arquivos
    pasta_dados = "dados"
    if os.path.exists(pasta_dados):
        json_files = glob.glob(f"{pasta_dados}/*.json")
        csv_files = glob.glob(f"{pasta_dados}/*.csv")
        
        print(f"\n{Cores.VERDE}ğŸ“ˆ ESTATÃSTICAS:{Cores.RESET}")
        print(f"   ğŸ“„ Arquivos JSON: {len(json_files)}")
        print(f"   ğŸ“Š Arquivos CSV: {len(csv_files)}")
        
        if json_files:
            latest_json = max(json_files, key=os.path.getctime)
            with open(latest_json, 'r', encoding='utf-8') as f:
                import json
                urls = json.load(f)
            print(f"   ğŸ•·ï¸  URLs coletadas: {len(urls)}")

def pausar():
    """Pausa a execuÃ§Ã£o para o usuÃ¡rio ler"""
    input(f"\n{Cores.MAGENTA}Pressione ENTER para continuar...{Cores.RESET}")

def main():
    """FunÃ§Ã£o principal do programa"""
    while True:
        limpar_terminal()
        mostrar_banner()
        mostrar_menu()
        
        escolha = obter_escolha()
        
        if escolha == "1":
            executar_coleta_urls()
        elif escolha == "2":
            executar_extracao_dados()
        elif escolha == "3":
            executar_coleta_completa()
        elif escolha == "4":
            listar_arquivos_gerados()
        elif escolha == "5":
            limpar_dados_antigos()
        elif escolha == "6":
            mostrar_sobre()
        elif escolha == "7":
            print(f"\n{Cores.VERDE}ğŸ‘‹ Obrigado por usar o Scraping PerdigÃ£o!{Cores.RESET}")
            break
        else:
            print(f"\n{Cores.VERMELHO}âŒ OpÃ§Ã£o invÃ¡lida! Digite um nÃºmero de 1 a 7.{Cores.RESET}")
        
        pausar()

if __name__ == "__main__":
    main() 